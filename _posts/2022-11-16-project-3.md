# Project 3 - News Popularity Data

Link to my rendered project Readme file : [**here**](https://sbgadhwala.github.io/ST558_Project3/)
The above file has the link to each document created for this project.

Link to my project 3 repository : [**here**](https://github.com/sbgadhwala/ST558_Project3/)

# Overview  

I finished my [third project](https://sbgadhwala.github.io/ST558_Project3/) for the ST558: Data Science for Statisticians course that revolved around doing some exploratoey Data Analysis and modelling for a data set on news articles. The target variable for this project was the number of shares each type of news article had. The types of articles that are dealt with in this project are:
  *  Technology
  *  Lifestyle
  *  Entertainment
  *  Business
  *  Social Media
  *  World

Initially the data set containing details about all these articles is taken in consideration, and using the **params** function feature in YML header in R markdown, the data set related just with one particular type of article is fetched, and is repeated for all types of articles. The Render function included in the Readme files depicts how that is achieved.

We were interested in predicting the number of shares for each article, hence we had to make sure that the response variable had a proper distribution. Up on doing inital exploratory data analysis, it was found that the number of shares in the data was skewed, and hence to remedy that, we took the logarithmic transformation of the response variable, and built all our models using that variable as the reponse variable.

## Linear Models
Since we were dealing with prediction of shares for each type of articles, we needed a set of predicting variables for the modelling. This data set had a huge dimensionality, and hence proper variable selection and substituion became imminent. We intially ran a linear regression model that had all the available variables, and found the statistically significant variables from that, and automated the technique to use it in a subsequent model. The most statistically significant variables were then used to build a simple multiple linear regression model. 

After the linear regression model, a LASSO model was built that provides an improvement over the linear regression model in cases with less number of variables. This became true when we used only the statistically significant variables from the first step. The statistics included in the project depicts that the LASSO model overall proved to be a good improvement over the linear regression model.

## Ensemble Models
After fitting LASSO model, we then moved to the ensemble learning methods. The first model built was the Random Forest model. 
Moving to the ensemble learning method, we decided to try a new approach for best variable selection. Before fitting any models, we decided to create Principle Components from all the variables in the data set, and use the first n number of PCs that explained a good enough variance in the data set (at least 80%). We then used the created PCs to fit a random forest model with log shares as the target variable, and **mtry** as the tuning parameter. In some cases this model performed better than previous models, in cases not. 

The last model that we built was the Boosted Tree model. In this, we used all the available variables to create the model. Since boosted tree works on slow learning of the trees from the best variables, we decided to let the model select its variables. We also used tuned several **hyperparameters** to select a "best" model.

# Comparing All Models
